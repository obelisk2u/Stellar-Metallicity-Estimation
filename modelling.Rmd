```{r}
library(dplyr)
library(caret)
library(lme4)
library(rstanarm)
library(ggcorrplot)
library(car)
library(robust)
library(performance)
set.seed(123)
```


Load data function
```{r}
read_data <- function() {
  data <- read.csv("./data/star_data.csv")
  df <- na.omit(data)
  
  colnames(df) <- c("tmp", "mh", "logg", "mag", "ra", "dec", "par", "ra_e", "dec_e", "par_e", "logg_low", "logg_up", "mh_low", "mh_up","tmp_low", "tmp_up", "blue_mag", "red_mag", "rad_vel")

  #make confidence intervals for mh and logg
  df$int_mh <- df$mh_up - df$mh_low
  df$int_logg <- df$logg_up - df$logg_low
  df$int_tmp <- df$tmp_up - df$tmp_low
  
  #calculate distance
  df$d <- abs(1000/df$par)
  
  #convert apparent mag to absolute
  df$mag <- df$mag - 5*log10(df$d) + 5
  
  #calculate luminosity
  l_sun <- 3.828e26
  df$l <- l_sun * 10^((4.83-df$mag)/2.5)
  
  #extract coordinate data and corresponding errors
  coords <- df |>
    filter(abs(d) < 25000, int_tmp < 24, int_mh < 0.0476, int_logg < 0.025) |>
    select(ra, dec, par, par_e, dec_e, ra_e, d)
  
  coords$ra_rad <- coords$ra*pi/180
  coords$dec_rad <- coords$dec*pi/180
  
  coords$x <- coords$d * cos(coords$dec_rad) * cos(coords$ra_rad)
  coords$y <- coords$d * cos(coords$dec_rad) * sin(coords$ra_rad)
  coords$z <- coords$d * sin(coords$dec_rad)
  
  coords <- coords |> filter(z<0)
  #remove used columns for space efficiency
  df <- df |> 
    filter(abs(d) < 25000, int_tmp < 24, int_mh < 0.0476, int_logg < 0.025, par_e < 0.0132) |>
    select(tmp, d, mh, logg, mag, l, rad_vel) 
  
  #preproc_l <- preProcess(df, method = c("center", "scale"))
  #df <- predict(preproc_l, df)
  #df <- df[1:50,]
  coords <- coords[1:300,]
  return(df)
}
```

Run Linear Model
```{r}
df<-read_data()
model_l <- lm(mh ~ d + tmp + mag + l + rad_vel, data = df)
qqnorm(residuals(model_l))
qqline(residuals(model_l), col = "red")
hist(residuals(model_l), main = "Histogram of Linear Model Residuals", xlab = "Residuals", xlim = c(-1, 1),breaks = 20)

plot(fitted(model_l), residuals(model_l), 
     main = 'Residuals vs. Fitted Values: Checking for Linearity',
     xlab = 'Fitted Values',
     ylab = 'Residuals')
abline(h = 0, col = "red", lwd = 2)


library(lmtest)

summary(model_l)
dwtest(model_l)
bptest(model_l)
ggplot(df, aes(x = d, y = mh)) +
  geom_point() +     
  labs(x = 'Distance (pc)', y='Metallicity [Fe/H]', title = 'Linear Relationship Between Distance and Metallicity') +
  xlim(0,1500) +
  geom_smooth(method = "lm",         
  formula = y ~ x,
  color = "blue",         
  se = TRUE)
shapiro.test(model_l$residuals)

#calculate MSE
observed <- df$mh
predicted <- predict(model_l)
mse <- mean((observed - predicted)^2)
print(mse)

#calculate null mse
observed <- df$mh
mean_y <- mean(observed)
null_mse <- mean((observed - mean_y)^2)
print(null_mse)
```

Create Binary Classification and Run Logistic Regression
```{r}
df <- read_data()
df$mh_bin <- factor(ifelse(df$mh > -0.2212, 1, 0))

model_log <- glm(mh_bin ~ d + tmp + mag + l + rad_vel, data = df, family = binomial(link = "logit"))
summary(model_log)
vif(model_log)
ggplot(df, aes(x=tmp, y=mh_bin)) + 
  geom_point() +
  labs(y = 'Binary Metallicity [Fe/H]', x ='Temperature (K)', title = 'Temperature vs. Binary Metallicity (Above -0.22)')

#plot residuals
residuals <- residuals(model_log, type = "pearson")
plot(residuals(model_log, type = "pearson"))

#Predictions
predictions <- predict(model_log, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
table(df$mh_bin, predicted_class)

#check that continuous predictors should have a linear relationship with the log-odds
plot(df$tmp, residuals, main = "Residuals vs Predictor1", xlab = "Predictor1", ylab = "Residuals")

#check for dispersion
dispersion <- sum(residuals(model_log, type = "pearson")^2) / model_log$df.residual
print(dispersion)

#run quasibinomial because dispersion is slightly higher than 1
model <- glm(mh_bin ~ d + tmp + mag + l + rad_vel, family = quasibinomial, data = df)
summary(model)
summary(model_log)

#confusion matrix for quasibinomial
predictions <- predict(model, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
table(df$mh_bin, predicted_class)
```

Check for Multicollinearity
```{r}
corr_matrix <- cor(df[, c("d", "tmp", "logg", "mag", "l", "blue_mag", "red_mag", "rad_vel")])
ggcorrplot(corr_matrix, lab = TRUE)
vif(model_log)
```



Run Linear Mixed Effects Model
null hypotheses: the mean values of the differnt groups do not differ, one factor has no influence on the effect of the other factor
```{r}
preproc_l <- preProcess(df, method = c("center", "scale"))
df_norm <- predict(preproc_l, df)
df_norm <- df_norm |> select(-levels)
df_norm <- cbind(df_norm, levels)
model_lme <- lmer(mh ~ d + tmp + mag + l + rad_vel + (1 | levels), data = df_norm)
summary(model_lme)
AIC(model_l, model_lme)
BIC(model_l, model_lme)

#check distribution of metallicity across distances
df$levels<-factor(df$levels)
ggplot(df, aes(x = mh, fill = levels)) +
  geom_density(alpha = 0.5) +  # alpha for transparency
  labs(title = "Distribution of Metallicity Values Grouped by Distance", x = "Metallicity", y = "Density") +
  scale_fill_manual(values = c("red", "blue", "green", "purple")) +
  theme_minimal()

#plot residuals
residuals <- resid(model_lme)
fitted_values <- fitted(model_lme)
ggplot(data = data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Linear Mixed Model Residual Plot", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

#Random scatter around 0 (no clear pattern) to indicate linearity. No funnel shape (homoscedasticity).
qqnorm(residuals, main = "Q-Q Plot of Residuals for LMM")
qqline(residuals, col = "red", lwd = 2)
```



Create hierarchy
```{r}
df <-read_data()
summary(df$d)
df$levels <- 0
df$levels <- ifelse(df$d > 331.28 & df$d <= 471.47, 1, df$levels)
df$levels <- ifelse(df$d > 471.47 & df$d <= 654.54, 2, df$levels)
df$levels <- ifelse(df$d > 653.54, 3, df$levels)
levels <- factor(df$levels)
```

Multilevel linear models
```{r}
#complete pooling (just regular linear regression)
model_c <- lm(mh ~ d + tmp + mag + l + rad_vel, data = df)
mse_c <- mse(model_c)
mse_c
AIC(model_c)
BIC(model_c)

#partial pooling
model_p <- lmer(mh ~ d + tmp + mag + l + rad_vel + (1|levels), data = df)
mse_p <- mse(model_p)
mse_p
AIC(model_p)
BIC(model_p)

#no pooling
model_n <- lm(mh ~ d + tmp + mag + l + rad_vel + levels - 1, data = df)
mse_n <- mse(model_n)
mse_n
AIC(model_n)
BIC(model_n)

#null
model <- lm(mh ~ 1,data = df)
mse <- mse(model)
mse
AIC(model)
BIC(model)
```

https://www.sciencedirect.com/science/article/pii/S2213133715000360
https://arxiv.org/pdf/1707.05834    
https://ned.ipac.caltech.edu/level5/Wall2/Wal3_1.html
1929 paper [citation 1]
https://academic.oup.com/mnras/article/484/2/2341/5288001 statistical properties of stars metllicity
https://www.aanda.org/articles/aa/full_html/2022/11/aa40995-21/aa40995-21.html#F4 
https://www.aanda.org/articles/aa/full_html/2021/06/aa40536-21/aa40536-21.html#:~:text=At%20low%20temperatures%2C%20the%20opacity,4. [citation 2]
https://www.sciencedirect.com/science/article/pii/S2213133715000360#bbr000170 [citation 3]










